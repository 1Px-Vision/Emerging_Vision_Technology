{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVdqdm0Jzj2T"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import torch\n",
        "import torch.utils\n",
        "import torch.utils.data\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from contextlib import contextmanager\n",
        "from timeit import default_timer\n",
        "from test import *  # FIXME: better name\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "from scipy.linalg import hadamard\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import time\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR0bzNX-z6WD"
      },
      "source": [
        "@contextmanager\n",
        "def elapsed_timer():\n",
        "    start = default_timer()\n",
        "    elapser = lambda: default_timer() - start\n",
        "    yield lambda: elapser()\n",
        "    end = default_timer()\n",
        "    elapser = lambda: end-start\n",
        "\n",
        "\n",
        "def run_omp(X, y, n_nonzero_coefs, precompute=True, tol=0.0, normalize=False, fit_intercept=False, alg='naive'):\n",
        "    if not isinstance(X, torch.Tensor):\n",
        "        X = torch.as_tensor(X)\n",
        "        y = torch.as_tensor(y)\n",
        "\n",
        "    if fit_intercept or normalize:\n",
        "        X = X.clone()\n",
        "        assert not isinstance(precompute, torch.Tensor), \"If user pre-computes XTX they can also pre-normalize X\" \\\n",
        "                                                         \" as well, so normalize and fit_intercept must be set false.\"\n",
        "\n",
        "    if fit_intercept:\n",
        "        X = X - X.mean(0)\n",
        "        y = y - y.mean(1)[:, None]\n",
        "\n",
        "    # To keep a good condition number on X, especially with Cholesky compared to LU factorization,\n",
        "    # we should probably always normalize it (OMP is invariant anyways)\n",
        "    if normalize is True:\n",
        "        normalize = (X * X).sum(0).sqrt()  # User can also just optionally supply pre-computed norms.\n",
        "        X /= normalize[None, :]  # Save compute if already normalized!\n",
        "\n",
        "    if precompute is True or alg == 'v0':\n",
        "        precompute = X.T @ X\n",
        "\n",
        "    # If n_nonzero_coefs is equal to M, one should just return lstsq\n",
        "    if alg == 'naive':\n",
        "        sets, solutions, lengths = omp_naive(X, y, n_nonzero_coefs=n_nonzero_coefs, XTX=precompute, tol=tol)\n",
        "    elif alg == 'v0':\n",
        "        sets, solutions, lengths = omp_v0(X, y, n_nonzero_coefs=n_nonzero_coefs, XTX=precompute, tol=tol)\n",
        "\n",
        "    solutions = solutions.squeeze(-1)\n",
        "    if normalize is not False:\n",
        "        solutions /= normalize[sets]\n",
        "\n",
        "    xests = y.new_zeros(y.shape[0], X.shape[1])\n",
        "    if lengths is None:\n",
        "        xests[torch.arange(y.shape[0], dtype=sets.dtype, device=sets.device)[:, None], sets] = solutions\n",
        "    else:\n",
        "        for i in range(y.shape[0]):\n",
        "            xests[i, sets[i, :lengths[i]]] = solutions[i, :lengths[i]]\n",
        "\n",
        "    return xests\n",
        "\n",
        "def batch_mm(matrix, matrix_batch, return_contiguous=True):\n",
        "    \"\"\"\n",
        "    :param matrix: Sparse or dense matrix, size (m, n).\n",
        "    :param matrix_batch: Batched dense matrices, size (b, n, k).\n",
        "    :return: The batched matrix-matrix product, size (m, n) x (b, n, k) = (b, m, k).\n",
        "    \"\"\"\n",
        "    batch_size = matrix_batch.shape[0]\n",
        "    # Stack the vector batch into columns. (b, n, k) -> (n, b, k) -> (n, b*k)\n",
        "    vectors = matrix_batch.transpose([1, 0, 2]).reshape(matrix.shape[1], -1)\n",
        "\n",
        "    # A matrix-matrix product is a batched matrix-vector product of the columns.\n",
        "    # And then reverse the reshaping. (m, n) x (n, b*k) = (m, b*k) -> (m, b, k) -> (b, m, k).\n",
        "    if return_contiguous:\n",
        "        result = np.empty_like(matrix_batch, shape=(batch_size, matrix.shape[0], matrix_batch.shape[2]))\n",
        "        np.matmul(matrix, vectors, out=result.transpose([1, 0, 2]).reshape(matrix.shape[0], -1))\n",
        "    else:\n",
        "        result = (matrix @ vectors).reshape(matrix.shape[0], batch_size, -1).transpose([1, 0, 2])\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def innerp(x, y=None, out=None):\n",
        "    if y is None:\n",
        "        y = x\n",
        "    if out is not None:\n",
        "        out = out[:, None, None]  # Add space for two singleton dimensions.\n",
        "    return torch.matmul(x[..., None, :], y[..., :, None], out=out)[..., 0, 0]\n",
        "\n",
        "def cholesky_solve(ATA, ATy):\n",
        "    if ATA.dtype == torch.half or ATy.dtype == torch.half:\n",
        "        return ATy.to(torch.float).cholesky_solve(torch.cholesky(ATA.to(torch.float))).to(ATy.dtype)\n",
        "    return ATy.cholesky_solve(torch.cholesky(ATA)).to(ATy.dtype)\n",
        "\n",
        "\n",
        "def omp_naive(X, y, n_nonzero_coefs):\n",
        "    XT = np.asfortranarray(X.T)\n",
        "    y = np.ascontiguousarray(y.T)  # TODO: Maybe this is not the fastest way to do it\n",
        "    r = y.copy()\n",
        "    sets = np.zeros((n_nonzero_coefs, y.shape[0]), dtype=np.int32)\n",
        "\n",
        "    ATs = np.empty_like(y, shape=(y.shape[0], n_nonzero_coefs, X.shape[0]))\n",
        "    # Trade b*k^2+bk memory for much less compute time. (This has to be done anyways, since we are batching, otherwise one could just permute columns of X in-place, as in https://github.com/scikit-learn/scikit-learn/blob/15a949460dbf19e5e196b8ef48f9712b72a3b3c3/sklearn/linear_model/_omp.py#L28 )\n",
        "    ATAs = np.empty_like(r, shape=(y.shape[0], n_nonzero_coefs, n_nonzero_coefs))\n",
        "    ATAs[:] = np.identity(n_nonzero_coefs, dtype=ATAs.dtype)\n",
        "\n",
        "    # ATAsPacked = ATAs[(b_indices,) + np.triu_indices(n_nonzero_coefs)].T.copy()\n",
        "    tri_idx = np.tril_indices(n_nonzero_coefs)\n",
        "    ATAsPacked = ATAs[:, tri_idx[0], tri_idx[1]].transpose([1, 0])\n",
        "    ATys = np.zeros_like(r, shape=(y.shape[0], n_nonzero_coefs, 1))  # .transpose([1, 0, 2])\n",
        "    xests = np.zeros_like(y, shape=(y.shape[0], X.shape[1]))\n",
        "    innerp = lambda x, y=None, out=None: np.einsum('bi,bi->b', x, x if y is None else y, out=out)\n",
        "    for k in range(n_nonzero_coefs):\n",
        "        projections = batch_mm(XT, r[:, :, None]).squeeze(-1)\n",
        "        sets[k, :] = get_max_projections_blas(projections)\n",
        "        # We will now update the following:\n",
        "        AT = ATs[:, :k + 1, :] # A.transpose([0, 2, 1])\n",
        "        ATA = ATAs[:, :k + 1, :k + 1]\n",
        "        ATy = ATys[:, :k + 1]\n",
        "\n",
        "        # Update As with the new column we add.\n",
        "        updateA = XT[sets[k, :], :]\n",
        "        AT[:, k, :] = updateA\n",
        "        # Update ATy\n",
        "        innerp(updateA, y, out=ATy[:, k, 0])\n",
        "\n",
        "        if True:\n",
        "            # Update ATAsPacked\n",
        "            packed_idx = k*(k-1)//2\n",
        "            np.matmul(AT[:, :k+1, :], updateA[:, :, None], out=ATAsPacked[k + packed_idx:packed_idx+2*k+1, :].T[:, :, None])\n",
        "            solutions = ATy.transpose([0, 2, 1]).copy().transpose([0, 2, 1])  # We need it in fortran order.\n",
        "            ppsv(np.ascontiguousarray(ATAsPacked[:packed_idx+2*k+1, :].T), solutions)\n",
        "        else:\n",
        "            # Update ATAs\n",
        "            np.matmul(AT[:, :k+1, :], updateA[:, :, None], out=ATA[:, k, :k+1, None])  # We could use the following to dynamically select order: ATA[:, k, :k].strides[-1], ATA[:, :k, k].strides[-1]\n",
        "            ATA[:, :k, k] = ATA[:, k, :k]\n",
        "            solutions = np.linalg.solve(ATA, ATy)\n",
        "\n",
        "        r[:] = y - (AT.transpose([0, 2, 1]) @ solutions).squeeze(-1)\n",
        "\n",
        "    else:\n",
        "        xests[np.arange(r.shape[0], dtype=sets.dtype)[:, None], sets.transpose([1, 0])] = solutions.squeeze(-1)\n",
        "\n",
        "    return xests\n",
        "\n",
        "\n",
        "def omp_v0(X, y, XTX, n_nonzero_coefs=None, tol=None, inverse_cholesky=True):\n",
        "    B = y.shape[0]\n",
        "    normr2 = innerp(y)  # Norm squared of residual.\n",
        "    projections = (X.transpose(1, 0) @ y[:, :, None]).squeeze(-1)\n",
        "    sets = y.new_zeros(n_nonzero_coefs, B, dtype=torch.int64)\n",
        "\n",
        "    if inverse_cholesky:\n",
        "        F = torch.eye(n_nonzero_coefs, dtype=y.dtype, device=y.device).repeat(B, 1, 1)\n",
        "        a_F = y.new_zeros(n_nonzero_coefs, B, 1)\n",
        "\n",
        "    D_mybest = y.new_empty(B, n_nonzero_coefs, XTX.shape[0])\n",
        "    temp_F_k_k = y.new_ones((B, 1))\n",
        "\n",
        "    if tol:\n",
        "        result_lengths = sets.new_zeros(y.shape[0])\n",
        "        result_solutions = y.new_zeros((y.shape[0], n_nonzero_coefs, 1))\n",
        "        finished_problems = sets.new_zeros(y.shape[0], dtype=torch.bool)\n",
        "\n",
        "    for k in range(n_nonzero_coefs+bool(tol)):\n",
        "        # STOPPING CRITERIA\n",
        "        if tol:\n",
        "            problems_done = normr2 <= tol\n",
        "            if k == n_nonzero_coefs:\n",
        "                problems_done[:] = True\n",
        "\n",
        "            if problems_done.any():\n",
        "                new_problems_done = problems_done & ~finished_problems\n",
        "                finished_problems.logical_or_(problems_done)\n",
        "                result_lengths[new_problems_done] = k\n",
        "                if inverse_cholesky:\n",
        "                    result_solutions[new_problems_done, :k] = F[new_problems_done, :k, :k].permute(0, 2, 1) @ a_F[:k, new_problems_done].permute(1, 0, 2)\n",
        "                else:\n",
        "                    assert False, \"inverse_cholesky=False with tol != None is not handled\"\n",
        "                if problems_done.all():\n",
        "                    return sets.t(), result_solutions, result_lengths\n",
        "\n",
        "        sets[k] = projections.abs().argmax(1)\n",
        "        # D_mybest[:, k, :] = XTX[gamma[k], :]  # Same line as below, but significantly slower. (prob. due to the intermediate array creation)\n",
        "        torch.gather(XTX, 0, sets[k, :, None].expand(-1, XTX.shape[1]), out=D_mybest[:, k, :])\n",
        "        if k:\n",
        "            D_mybest_maxindices = D_mybest.permute(0, 2, 1)[torch.arange(D_mybest.shape[0], dtype=sets.dtype, device=sets.device), sets[k], :k]\n",
        "            torch.rsqrt(1 - innerp(D_mybest_maxindices), out=temp_F_k_k[:, 0])  # torch.exp(-1/2 * torch.log1p(-inp), temp_F_k_k[:, 0])\n",
        "            D_mybest_maxindices *= -temp_F_k_k  # minimal operations, exploit linearity\n",
        "            D_mybest[:, k, :] *= temp_F_k_k\n",
        "            D_mybest[:, k, :, None].baddbmm_(D_mybest[:, :k, :].permute(0, 2, 1), D_mybest_maxindices[:, :, None])\n",
        "\n",
        "\n",
        "        temp_a_F = temp_F_k_k * torch.gather(projections, 1, sets[k, :, None])\n",
        "        normr2 -= (temp_a_F * temp_a_F).squeeze(-1)\n",
        "        projections -= temp_a_F * D_mybest[:, k, :]\n",
        "        if inverse_cholesky:\n",
        "            a_F[k] = temp_a_F\n",
        "            if k:  # Could maybe a speedup from triangular mat mul kernel.\n",
        "                torch.bmm(D_mybest_maxindices[:, None, :], F[:, :k, :], out=F[:, k, None, :])\n",
        "                F[:, k, k] = temp_F_k_k[..., 0]\n",
        "    else:\n",
        "        if inverse_cholesky:\n",
        "            solutions = F.permute(0, 2, 1) @ a_F.squeeze(-1).transpose(1, 0)[:, :, None]\n",
        "        else:\n",
        "            AT = X.T[sets.T]\n",
        "            solutions = cholesky_solve(AT @ AT.permute(0, 2, 1), AT @ y.T[:, :, None])\n",
        "\n",
        "    return sets.t(), solutions, None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "VBU7y8i70SLT",
        "outputId": "a4ff8f9c-f419-4322-e432-36208a1f5f9e"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # TODO:\n",
        "\n",
        "    #measurement\n",
        "    #m_data = scipy.io.loadmat('measured_64.mat')\n",
        "    #mdata = m_data['measurements_hh8_64']\n",
        "    #dictionary\n",
        "    m_dict = scipy.io.loadmat('/content/diccionarios16x16.mat')\n",
        "    mdict = m_dict['M_frame']\n",
        "    N1,N2,N3=mdict.shape\n",
        "\n",
        "    mdict_x=np.reshape(mdict,(N3,N3))#NxN,NxN\n",
        "\n",
        "    frame=scipy.io.loadmat('/content/dat16.mat')\n",
        "    m_frame=frame['measurements_n_16']\n",
        "    m_frame_1=np.zeros((1,N3))#1,NxN\n",
        "    M,N=m_frame.shape\n",
        "    tol =1e-3\n",
        "    k = 0\n",
        "    n_samples=N3 #NxN\n",
        "    frames = []\n",
        "    img_array = []\n",
        "    fig = plt.figure()\n",
        "    plt.axis('off')\n",
        "    height, width=256,256\n",
        "    #out1 = cv2.VideoWriter('output1.avi', cv2.VideoWriter_fourcc(*'DIVX'), 10, (width, height))\n",
        "\n",
        "    #with elapsed_timer() as elapsed:\n",
        "\n",
        "    mdata =m_frame\n",
        "    n_components, n_features = N3, N3  #NxN,NxN\n",
        "\n",
        "    n_nonzero_coefs = N3-len(np.where(mdata==0)[0])#NxN-\n",
        "    y=mdata.T\n",
        "    X=mdict_x.astype('float')\n",
        "    X=X.T\n",
        "\n",
        "    with elapsed_timer() as elapsed:\n",
        "        xests_v0 = run_omp(torch.as_tensor(X.copy()), torch.as_tensor(y.copy()), n_nonzero_coefs-k, normalize=True, fit_intercept=False, tol=tol, alg='v0')\n",
        "        xests_v0=np.abs(xests_v0)\n",
        "\n",
        "    plt.axis('off')\n",
        "    frames.append([plt.imshow(np.reshape(np.array(xests_v0),(N1,N2)), cmap=cm.Greys_r,animated=True)])\n",
        "    plt.savefig('temp.png',bbox_inches='tight', pad_inches=0)\n",
        "\n",
        "    print('Done Video')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Video\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}